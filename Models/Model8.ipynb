{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUbp8-MVIYHv",
        "outputId": "03517437-927f-4fa1-d5b8-fe5ca2386cab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEpQBx34_FqI"
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
        "from keras.initializers import HeNormal\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzx7ZhoU5-bW"
      },
      "source": [
        "from keras.applications.resnet import ResNet50, decode_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP3cL8zt7Ha_",
        "outputId": "ae8a7343-d3ff-4882-e46b-5156097976ed"
      },
      "source": [
        "pathToData = \"drive/MyDrive/CS 230 Final Project/ResNet Data/\"\n",
        "print(pathToData + \"trainRes_X.p\")\n",
        "pathToModels = \"drive/MyDrive/CS 230 Final Project/SavedModelsFromTraining/\"\n",
        "print(pathToModels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/CS 230 Final Project/ResNet Data/trainRes_X.p\n",
            "drive/MyDrive/CS 230 Final Project/SavedModelsFromTraining/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfeiQt5A7Psv",
        "outputId": "416f5261-b530-4624-fbc7-c745e52c33b1"
      },
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "# load the train dataset\n",
        "X_train = pickle.load(open(pathToData+\"trainRes_X.p\", 'rb'))\n",
        "y_trainUnflat = pickle.load(open(pathToData+\"trainRes_Y.p\", 'rb'))\n",
        "y_train = y_trainUnflat.reshape(y_trainUnflat.shape[0],-1)\n",
        "y_train = mlb.fit_transform(y_train)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "# load the dev dataset\n",
        "X_dev = pickle.load(open(pathToData+\"devRes_X.p\", 'rb'))\n",
        "y_devUnflat = pickle.load(open(pathToData+\"devRes_Y.p\", 'rb'))\n",
        "y_dev = y_devUnflat.reshape(y_devUnflat.shape[0],-1)\n",
        "y_dev = mlb.fit_transform(y_dev)\n",
        "\n",
        "print(X_dev.shape)\n",
        "print(y_dev.shape)\n",
        "\n",
        "# load the test dataset\n",
        "X_test = pickle.load(open(pathToData+\"testRes_X.p\", 'rb'))\n",
        "y_testUnflat = pickle.load(open(pathToData+\"testRes_Y.p\", 'rb'))\n",
        "y_test = y_testUnflat.reshape(y_testUnflat.shape[0],-1)\n",
        "y_test = mlb.fit_transform(y_test)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4246, 224, 224, 3)\n",
            "(4246, 3)\n",
            "(910, 224, 224, 3)\n",
            "(910, 3)\n",
            "(910, 224, 224, 3)\n",
            "(910, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwNzPKfw7fl8",
        "outputId": "ae9e8bf4-8d5c-42ac-ff39-0c65260146ec"
      },
      "source": [
        "print(y_trainUnflat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 1 ... 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSpPSzxy7hB2",
        "outputId": "5ae2d47a-955a-4cdd-81db-6d57b71f767b"
      },
      "source": [
        "numExamples = X_train.shape[0]\n",
        "print(numExamples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiUsW9a_7jPV",
        "outputId": "593389a5-f236-4b35-838f-cae3413f601e"
      },
      "source": [
        "print(X_train.shape[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFJQZDElGtPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade18d00-406d-4054-c406-5fe45c277b54"
      },
      "source": [
        "print(X_train.shape[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4jqkMki9zf4"
      },
      "source": [
        "model = ResNet50(weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDcB5x5--gtK"
      },
      "source": [
        "first_layer_weights = model.layers[2].get_weights()\n",
        "print(first_layer_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jO5sNpwTRDG"
      },
      "source": [
        "predictions = Dense(3, activation='softmax')(model.layers[-2].output)\n",
        "newModel = Model(inputs=model.input, outputs=predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwKq5UazTs7G",
        "outputId": "e9fa681e-a095-4339-d5d1-e35a446ff8f4"
      },
      "source": [
        "counter = 0\n",
        "for layer in newModel.layers:\n",
        "  counter += 1\n",
        "print(counter)\n",
        "\n",
        "for layer in newModel.layers[:59]:\n",
        "  layer.trainable = False\n",
        "\n",
        "countFalse = 0\n",
        "countTrue = 0\n",
        "for layer in newModel.layers:\n",
        "  if layer.trainable == False:\n",
        "    countFalse += 1\n",
        "  if layer.trainable == True:\n",
        "    countTrue += 1\n",
        "print(countFalse)\n",
        "print(countTrue)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "177\n",
            "59\n",
            "118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HOhbg0J-sRc",
        "outputId": "20047740-91da-4603-999b-4d91e2da7a10"
      },
      "source": [
        "newModel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 3)            6147        ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,593,859\n",
            "Trainable params: 22,652,419\n",
            "Non-trainable params: 941,440\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjxEr0MBU5wJ"
      },
      "source": [
        "first = newModel.layers[2].get_weights()\n",
        "print(first)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRPPBm9jJe68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e713e682-9b87-4a61-c1a7-9df06d859000"
      },
      "source": [
        "batchSizes = [100, 64, 32]\n",
        "numEpochs = 50\n",
        "print(batchSizes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100, 64, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo-xwUgNJibJ"
      },
      "source": [
        "trainAccuracy = []\n",
        "valAccuracy = []\n",
        "trainLoss = []\n",
        "valLoss = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccGQQvB5WYVW",
        "outputId": "70ddae7f-3244-4436-b568-2312bf4b2804"
      },
      "source": [
        "for batchSize in batchSizes:\n",
        "  print(\"BatchSize : \", batchSize)\n",
        "\n",
        "  firstPart = pathToModels+\"Model8weights_\"+str(batchSize)\n",
        "  checkpoint_filepath = firstPart+'.{epoch:02d}-{val_loss:.2f}.h5'\n",
        "  print(checkpoint_filepath)\n",
        "  model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_categorical_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "  newModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
        "  history = newM+++++++odel.fit(X_train, y_train, epochs=numEpochs, batch_size=batchSize, validation_data = (X_dev, y_dev), callbacks=[model_checkpoint_callback])\n",
        "  historyDict = history.history\n",
        "  #print(historyDict.keys())\n",
        "  trainAccuracy.append(historyDict['categorical_accuracy'])\n",
        "  valAccuracy.append(historyDict['val_categorical_accuracy'])\n",
        "  trainLoss.append(historyDict['loss'])\n",
        "  valLoss.append(historyDict['val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BatchSize :  100\n",
            "drive/MyDrive/CS 230 Final Project/SavedModelsFromTraining/Model8weights_100.{epoch:02d}-{val_loss:.2f}.h5\n",
            "Epoch 1/50\n",
            "43/43 [==============================] - ETA: 0s - loss: 1.1481 - categorical_accuracy: 0.5582"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r43/43 [==============================] - 90s 2s/step - loss: 1.1481 - categorical_accuracy: 0.5582 - val_loss: 46.5043 - val_categorical_accuracy: 0.4747\n",
            "Epoch 2/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.4725 - categorical_accuracy: 0.8231 - val_loss: 11.7039 - val_categorical_accuracy: 0.2022\n",
            "Epoch 3/50\n",
            "43/43 [==============================] - 63s 1s/step - loss: 0.2342 - categorical_accuracy: 0.9129 - val_loss: 1.6021 - val_categorical_accuracy: 0.5714\n",
            "Epoch 4/50\n",
            "43/43 [==============================] - 64s 1s/step - loss: 0.1367 - categorical_accuracy: 0.9515 - val_loss: 0.9571 - val_categorical_accuracy: 0.7582\n",
            "Epoch 5/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.1011 - categorical_accuracy: 0.9640 - val_loss: 2.5696 - val_categorical_accuracy: 0.6154\n",
            "Epoch 6/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0795 - categorical_accuracy: 0.9722 - val_loss: 1.5714 - val_categorical_accuracy: 0.7341\n",
            "Epoch 7/50\n",
            "43/43 [==============================] - 63s 1s/step - loss: 0.0424 - categorical_accuracy: 0.9870 - val_loss: 0.6947 - val_categorical_accuracy: 0.8670\n",
            "Epoch 8/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0369 - categorical_accuracy: 0.9875 - val_loss: 1.2415 - val_categorical_accuracy: 0.7253\n",
            "Epoch 9/50\n",
            "43/43 [==============================] - 63s 1s/step - loss: 0.0268 - categorical_accuracy: 0.9911 - val_loss: 0.4087 - val_categorical_accuracy: 0.9044\n",
            "Epoch 10/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0325 - categorical_accuracy: 0.9882 - val_loss: 0.6531 - val_categorical_accuracy: 0.8857\n",
            "Epoch 11/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0337 - categorical_accuracy: 0.9880 - val_loss: 0.7336 - val_categorical_accuracy: 0.8626\n",
            "Epoch 12/50\n",
            "43/43 [==============================] - 66s 2s/step - loss: 0.0212 - categorical_accuracy: 0.9934 - val_loss: 1.0909 - val_categorical_accuracy: 0.7846\n",
            "Epoch 13/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0223 - categorical_accuracy: 0.9911 - val_loss: 0.5516 - val_categorical_accuracy: 0.8923\n",
            "Epoch 14/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 0.0151 - categorical_accuracy: 0.9948 - val_loss: 1.0154 - val_categorical_accuracy: 0.8604\n",
            "Epoch 15/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 0.0164 - categorical_accuracy: 0.9936 - val_loss: 0.8584 - val_categorical_accuracy: 0.8791\n",
            "Epoch 16/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0610 - categorical_accuracy: 0.9828 - val_loss: 1.6983 - val_categorical_accuracy: 0.7637\n",
            "Epoch 17/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0505 - categorical_accuracy: 0.9819 - val_loss: 2.7674 - val_categorical_accuracy: 0.5429\n",
            "Epoch 18/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0206 - categorical_accuracy: 0.9929 - val_loss: 1.0948 - val_categorical_accuracy: 0.8176\n",
            "Epoch 19/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 0.0039 - categorical_accuracy: 0.9988 - val_loss: 0.8433 - val_categorical_accuracy: 0.8527\n",
            "Epoch 20/50\n",
            "43/43 [==============================] - 68s 2s/step - loss: 0.0014 - categorical_accuracy: 0.9998 - val_loss: 0.4985 - val_categorical_accuracy: 0.9077\n",
            "Epoch 21/50\n",
            "43/43 [==============================] - 63s 1s/step - loss: 2.7299e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4571 - val_categorical_accuracy: 0.9165\n",
            "Epoch 22/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 1.4470e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4637 - val_categorical_accuracy: 0.9165\n",
            "Epoch 23/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 9.1477e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4509 - val_categorical_accuracy: 0.9132\n",
            "Epoch 24/50\n",
            "43/43 [==============================] - 66s 2s/step - loss: 5.3970e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4435 - val_categorical_accuracy: 0.9143\n",
            "Epoch 25/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 6.0525e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4396 - val_categorical_accuracy: 0.9132\n",
            "Epoch 26/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 4.1762e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4376 - val_categorical_accuracy: 0.9132\n",
            "Epoch 27/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 3.9519e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4350 - val_categorical_accuracy: 0.9143\n",
            "Epoch 28/50\n",
            "43/43 [==============================] - 66s 2s/step - loss: 3.6547e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4331 - val_categorical_accuracy: 0.9143\n",
            "Epoch 29/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 3.4711e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4356 - val_categorical_accuracy: 0.9143\n",
            "Epoch 30/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 2.5680e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4359 - val_categorical_accuracy: 0.9143\n",
            "Epoch 31/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 3.3858e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4379 - val_categorical_accuracy: 0.9143\n",
            "Epoch 32/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 3.8238e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4405 - val_categorical_accuracy: 0.9154\n",
            "Epoch 33/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 2.5776e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4422 - val_categorical_accuracy: 0.9143\n",
            "Epoch 34/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 3.3691e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4437 - val_categorical_accuracy: 0.9143\n",
            "Epoch 35/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 1.9502e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4440 - val_categorical_accuracy: 0.9143\n",
            "Epoch 36/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 2.3017e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4462 - val_categorical_accuracy: 0.9143\n",
            "Epoch 37/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.4502e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4472 - val_categorical_accuracy: 0.9143\n",
            "Epoch 38/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.4246e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4481 - val_categorical_accuracy: 0.9143\n",
            "Epoch 39/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.6665e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4495 - val_categorical_accuracy: 0.9143\n",
            "Epoch 40/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.1197e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4505 - val_categorical_accuracy: 0.9143\n",
            "Epoch 41/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.2273e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4521 - val_categorical_accuracy: 0.9143\n",
            "Epoch 42/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.2659e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4529 - val_categorical_accuracy: 0.9143\n",
            "Epoch 43/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 9.5750e-06 - categorical_accuracy: 1.0000 - val_loss: 0.4533 - val_categorical_accuracy: 0.9143\n",
            "Epoch 44/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.0121e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4535 - val_categorical_accuracy: 0.9143\n",
            "Epoch 45/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 9.0976e-06 - categorical_accuracy: 1.0000 - val_loss: 0.4539 - val_categorical_accuracy: 0.9143\n",
            "Epoch 46/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.1445e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4557 - val_categorical_accuracy: 0.9143\n",
            "Epoch 47/50\n",
            "43/43 [==============================] - 62s 1s/step - loss: 1.5465e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4586 - val_categorical_accuracy: 0.9143\n",
            "Epoch 48/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 1.2966e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4621 - val_categorical_accuracy: 0.9143\n",
            "Epoch 49/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 1.2075e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4628 - val_categorical_accuracy: 0.9143\n",
            "Epoch 50/50\n",
            "43/43 [==============================] - 61s 1s/step - loss: 1.2402e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4632 - val_categorical_accuracy: 0.9143\n",
            "BatchSize :  64\n",
            "drive/MyDrive/CS 230 Final Project/SavedModelsFromTraining/Model8weights_64.{epoch:02d}-{val_loss:.2f}.h5\n",
            "Epoch 1/50\n",
            "67/67 [==============================] - 76s 1s/step - loss: 0.0955 - categorical_accuracy: 0.9694 - val_loss: 13.6337 - val_categorical_accuracy: 0.5154\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 64s 950ms/step - loss: 0.0439 - categorical_accuracy: 0.9852 - val_loss: 1.4724 - val_categorical_accuracy: 0.7934\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 69s 1s/step - loss: 0.0261 - categorical_accuracy: 0.9911 - val_loss: 0.9940 - val_categorical_accuracy: 0.8604\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 64s 960ms/step - loss: 0.0283 - categorical_accuracy: 0.9906 - val_loss: 0.7260 - val_categorical_accuracy: 0.8846\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 67s 1s/step - loss: 0.0568 - categorical_accuracy: 0.9814 - val_loss: 0.5604 - val_categorical_accuracy: 0.8681\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 64s 960ms/step - loss: 0.0287 - categorical_accuracy: 0.9918 - val_loss: 0.5994 - val_categorical_accuracy: 0.8923\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 64s 961ms/step - loss: 0.0110 - categorical_accuracy: 0.9969 - val_loss: 0.4459 - val_categorical_accuracy: 0.9077\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 62s 925ms/step - loss: 0.0078 - categorical_accuracy: 0.9974 - val_loss: 0.5198 - val_categorical_accuracy: 0.8901\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 64s 957ms/step - loss: 0.0019 - categorical_accuracy: 0.9998 - val_loss: 0.4688 - val_categorical_accuracy: 0.9121\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 62s 923ms/step - loss: 3.9925e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4930 - val_categorical_accuracy: 0.9066\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 64s 958ms/step - loss: 2.0464e-04 - categorical_accuracy: 1.0000 - val_loss: 0.4786 - val_categorical_accuracy: 0.9176\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 62s 924ms/step - loss: 8.0740e-05 - categorical_accuracy: 1.0000 - val_loss: 0.4964 - val_categorical_accuracy: 0.9154\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 62s 924ms/step - loss: 5.0551e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5024 - val_categorical_accuracy: 0.9176\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 62s 925ms/step - loss: 4.9149e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5071 - val_categorical_accuracy: 0.9176\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 64s 959ms/step - loss: 3.6106e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5138 - val_categorical_accuracy: 0.9187\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 62s 926ms/step - loss: 3.1218e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5176 - val_categorical_accuracy: 0.9187\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 62s 925ms/step - loss: 2.2144e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5192 - val_categorical_accuracy: 0.9187\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 62s 924ms/step - loss: 1.8153e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5204 - val_categorical_accuracy: 0.9187\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 62s 924ms/step - loss: 1.8314e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5209 - val_categorical_accuracy: 0.9187\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 64s 957ms/step - loss: 2.1418e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5232 - val_categorical_accuracy: 0.9198\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 62s 925ms/step - loss: 1.6345e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5217 - val_categorical_accuracy: 0.9176\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 62s 923ms/step - loss: 1.7429e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5240 - val_categorical_accuracy: 0.9198\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 1.2923e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5257 - val_categorical_accuracy: 0.9176\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 62s 921ms/step - loss: 1.2437e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5285 - val_categorical_accuracy: 0.9176\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 1.3189e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5302 - val_categorical_accuracy: 0.9176\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 62s 921ms/step - loss: 1.1570e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5333 - val_categorical_accuracy: 0.9176\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 9.2611e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5349 - val_categorical_accuracy: 0.9176\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 1.2553e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5370 - val_categorical_accuracy: 0.9176\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 62s 921ms/step - loss: 1.2908e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5378 - val_categorical_accuracy: 0.9176\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 7.5241e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5405 - val_categorical_accuracy: 0.9176\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 1.9679e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5447 - val_categorical_accuracy: 0.9176\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 1.0334e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5879 - val_categorical_accuracy: 0.9110\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 1.2724e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5733 - val_categorical_accuracy: 0.9132\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 1.0663e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5708 - val_categorical_accuracy: 0.9132\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 7.5275e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5670 - val_categorical_accuracy: 0.9154\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 62s 921ms/step - loss: 6.1006e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5685 - val_categorical_accuracy: 0.9165\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 62s 922ms/step - loss: 8.2536e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5653 - val_categorical_accuracy: 0.9165\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 62s 920ms/step - loss: 3.9428e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5662 - val_categorical_accuracy: 0.9165\n",
            "Epoch 39/50\n",
            "67/67 [==============================] - 61s 916ms/step - loss: 8.9072e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5661 - val_categorical_accuracy: 0.9154\n",
            "Epoch 40/50\n",
            "67/67 [==============================] - 61s 916ms/step - loss: 3.7442e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5678 - val_categorical_accuracy: 0.9165\n",
            "Epoch 41/50\n",
            "67/67 [==============================] - 61s 915ms/step - loss: 3.4325e-06 - categorical_accuracy: 1.0000 - val_loss: 0.5702 - val_categorical_accuracy: 0.9165\n",
            "Epoch 42/50\n",
            "67/67 [==============================] - 61s 914ms/step - loss: 2.9580e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5981 - val_categorical_accuracy: 0.9099\n",
            "Epoch 43/50\n",
            "67/67 [==============================] - 61s 913ms/step - loss: 0.3928 - categorical_accuracy: 0.8632 - val_loss: 6253.7065 - val_categorical_accuracy: 0.4747\n",
            "Epoch 44/50\n",
            "67/67 [==============================] - 61s 917ms/step - loss: 0.1734 - categorical_accuracy: 0.9388 - val_loss: 13.6784 - val_categorical_accuracy: 0.5077\n",
            "Epoch 45/50\n",
            "67/67 [==============================] - 62s 920ms/step - loss: 0.0254 - categorical_accuracy: 0.9925 - val_loss: 0.7673 - val_categorical_accuracy: 0.8780\n",
            "Epoch 46/50\n",
            "67/67 [==============================] - 62s 920ms/step - loss: 0.0138 - categorical_accuracy: 0.9955 - val_loss: 1.3406 - val_categorical_accuracy: 0.7396\n",
            "Epoch 47/50\n",
            "67/67 [==============================] - 62s 920ms/step - loss: 0.0044 - categorical_accuracy: 0.9986 - val_loss: 0.7543 - val_categorical_accuracy: 0.8912\n",
            "Epoch 48/50\n",
            "67/67 [==============================] - 62s 920ms/step - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.5306 - val_categorical_accuracy: 0.9011\n",
            "Epoch 49/50\n",
            "67/67 [==============================] - 62s 921ms/step - loss: 5.4918e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5636 - val_categorical_accuracy: 0.8978\n",
            "Epoch 50/50\n",
            "67/67 [==============================] - 62s 921ms/step - loss: 2.0229e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5557 - val_categorical_accuracy: 0.8945\n",
            "BatchSize :  32\n",
            "drive/MyDrive/CS 230 Final Project/SavedModelsFromTraining/Model8weights_32.{epoch:02d}-{val_loss:.2f}.h5\n",
            "Epoch 1/50\n",
            "133/133 [==============================] - 79s 529ms/step - loss: 0.0372 - categorical_accuracy: 0.9868 - val_loss: 0.9093 - val_categorical_accuracy: 0.8813\n",
            "Epoch 2/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 0.0569 - categorical_accuracy: 0.9809 - val_loss: 0.8587 - val_categorical_accuracy: 0.8516\n",
            "Epoch 3/50\n",
            "133/133 [==============================] - 69s 520ms/step - loss: 0.0331 - categorical_accuracy: 0.9885 - val_loss: 0.6505 - val_categorical_accuracy: 0.9077\n",
            "Epoch 4/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 0.0282 - categorical_accuracy: 0.9899 - val_loss: 0.7105 - val_categorical_accuracy: 0.8890\n",
            "Epoch 5/50\n",
            "133/133 [==============================] - 71s 535ms/step - loss: 0.0089 - categorical_accuracy: 0.9972 - val_loss: 0.6261 - val_categorical_accuracy: 0.8956\n",
            "Epoch 6/50\n",
            "133/133 [==============================] - 67s 500ms/step - loss: 0.0263 - categorical_accuracy: 0.9906 - val_loss: 1.6349 - val_categorical_accuracy: 0.7659\n",
            "Epoch 7/50\n",
            "133/133 [==============================] - 71s 534ms/step - loss: 0.0499 - categorical_accuracy: 0.9823 - val_loss: 0.7431 - val_categorical_accuracy: 0.8835\n",
            "Epoch 8/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 0.0173 - categorical_accuracy: 0.9932 - val_loss: 0.6265 - val_categorical_accuracy: 0.9033\n",
            "Epoch 9/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 0.0085 - categorical_accuracy: 0.9979 - val_loss: 0.6792 - val_categorical_accuracy: 0.8978\n",
            "Epoch 10/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 0.0133 - categorical_accuracy: 0.9948 - val_loss: 0.6621 - val_categorical_accuracy: 0.8901\n",
            "Epoch 11/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 0.0264 - categorical_accuracy: 0.9922 - val_loss: 0.6046 - val_categorical_accuracy: 0.8945\n",
            "Epoch 12/50\n",
            "133/133 [==============================] - 67s 500ms/step - loss: 0.0412 - categorical_accuracy: 0.9870 - val_loss: 0.8351 - val_categorical_accuracy: 0.8396\n",
            "Epoch 13/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 0.0105 - categorical_accuracy: 0.9972 - val_loss: 0.5928 - val_categorical_accuracy: 0.8978\n",
            "Epoch 14/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 0.0086 - categorical_accuracy: 0.9969 - val_loss: 0.5760 - val_categorical_accuracy: 0.9077\n",
            "Epoch 15/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 0.0031 - categorical_accuracy: 0.9988 - val_loss: 0.5126 - val_categorical_accuracy: 0.8846\n",
            "Epoch 16/50\n",
            "133/133 [==============================] - 67s 500ms/step - loss: 0.0111 - categorical_accuracy: 0.9958 - val_loss: 1.2042 - val_categorical_accuracy: 0.8659\n",
            "Epoch 17/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 0.0129 - categorical_accuracy: 0.9958 - val_loss: 0.6401 - val_categorical_accuracy: 0.8890\n",
            "Epoch 18/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 0.0162 - categorical_accuracy: 0.9943 - val_loss: 0.7444 - val_categorical_accuracy: 0.8868\n",
            "Epoch 19/50\n",
            "133/133 [==============================] - 71s 534ms/step - loss: 0.0248 - categorical_accuracy: 0.9932 - val_loss: 0.7483 - val_categorical_accuracy: 0.8824\n",
            "Epoch 20/50\n",
            "133/133 [==============================] - 67s 500ms/step - loss: 0.0253 - categorical_accuracy: 0.9911 - val_loss: 0.9606 - val_categorical_accuracy: 0.8560\n",
            "Epoch 21/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 0.0115 - categorical_accuracy: 0.9955 - val_loss: 0.5956 - val_categorical_accuracy: 0.8956\n",
            "Epoch 22/50\n",
            "133/133 [==============================] - 67s 500ms/step - loss: 0.0062 - categorical_accuracy: 0.9981 - val_loss: 0.9190 - val_categorical_accuracy: 0.8791\n",
            "Epoch 23/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 3.9804e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6278 - val_categorical_accuracy: 0.8956\n",
            "Epoch 24/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 3.0939e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6425 - val_categorical_accuracy: 0.9000\n",
            "Epoch 25/50\n",
            "133/133 [==============================] - 71s 535ms/step - loss: 2.2644e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6461 - val_categorical_accuracy: 0.8967\n",
            "Epoch 26/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 1.4774e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6400 - val_categorical_accuracy: 0.9000\n",
            "Epoch 27/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 1.8289e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6347 - val_categorical_accuracy: 0.8956\n",
            "Epoch 28/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 7.6124e-05 - categorical_accuracy: 1.0000 - val_loss: 0.6494 - val_categorical_accuracy: 0.8978\n",
            "Epoch 29/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 5.8734e-05 - categorical_accuracy: 1.0000 - val_loss: 0.6560 - val_categorical_accuracy: 0.8989\n",
            "Epoch 30/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 8.9368e-04 - categorical_accuracy: 0.9998 - val_loss: 0.7447 - val_categorical_accuracy: 0.8967\n",
            "Epoch 31/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 3.9798e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6898 - val_categorical_accuracy: 0.8956\n",
            "Epoch 32/50\n",
            "133/133 [==============================] - 66s 499ms/step - loss: 1.3103e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6784 - val_categorical_accuracy: 0.9033\n",
            "Epoch 33/50\n",
            "133/133 [==============================] - 66s 498ms/step - loss: 2.7244e-04 - categorical_accuracy: 1.0000 - val_loss: 0.6741 - val_categorical_accuracy: 0.9022\n",
            "Epoch 34/50\n",
            "133/133 [==============================] - 66s 499ms/step - loss: 0.0933 - categorical_accuracy: 0.9689 - val_loss: 621.0287 - val_categorical_accuracy: 0.3231\n",
            "Epoch 35/50\n",
            "133/133 [==============================] - 71s 535ms/step - loss: 0.0922 - categorical_accuracy: 0.9720 - val_loss: 0.6617 - val_categorical_accuracy: 0.8835\n",
            "Epoch 36/50\n",
            "133/133 [==============================] - 67s 502ms/step - loss: 0.0168 - categorical_accuracy: 0.9943 - val_loss: 0.5768 - val_categorical_accuracy: 0.9033\n",
            "Epoch 37/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 0.0012 - categorical_accuracy: 1.0000 - val_loss: 0.5236 - val_categorical_accuracy: 0.8901\n",
            "Epoch 38/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 4.3260e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5283 - val_categorical_accuracy: 0.8923\n",
            "Epoch 39/50\n",
            "133/133 [==============================] - 66s 500ms/step - loss: 3.8753e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5400 - val_categorical_accuracy: 0.9000\n",
            "Epoch 40/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 1.6034e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5366 - val_categorical_accuracy: 0.9000\n",
            "Epoch 41/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 1.1498e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5434 - val_categorical_accuracy: 0.8934\n",
            "Epoch 42/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 1.0791e-04 - categorical_accuracy: 1.0000 - val_loss: 0.5505 - val_categorical_accuracy: 0.8956\n",
            "Epoch 43/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 8.2010e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5529 - val_categorical_accuracy: 0.8934\n",
            "Epoch 44/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 9.9291e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5578 - val_categorical_accuracy: 0.9022\n",
            "Epoch 45/50\n",
            "133/133 [==============================] - 67s 502ms/step - loss: 6.1704e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5640 - val_categorical_accuracy: 0.8989\n",
            "Epoch 46/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 4.4978e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5667 - val_categorical_accuracy: 0.8945\n",
            "Epoch 47/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 4.8518e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5670 - val_categorical_accuracy: 0.8978\n",
            "Epoch 48/50\n",
            "133/133 [==============================] - 67s 502ms/step - loss: 3.3359e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5719 - val_categorical_accuracy: 0.8956\n",
            "Epoch 49/50\n",
            "133/133 [==============================] - 67s 502ms/step - loss: 4.2153e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5831 - val_categorical_accuracy: 0.8934\n",
            "Epoch 50/50\n",
            "133/133 [==============================] - 67s 501ms/step - loss: 3.3911e-05 - categorical_accuracy: 1.0000 - val_loss: 0.5803 - val_categorical_accuracy: 0.8967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQn6UHSO_XIa"
      },
      "source": [
        "best100 = load_model(pathToModels+\"Model8weights_100.20-0.50.h5\") #batch size 100, epoch 20 gave lowest non-overfit dev loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_h9AZ7R_XIb"
      },
      "source": [
        "predictions100 = best100.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc4LTOcL_XIc"
      },
      "source": [
        "# print(predictions)\n",
        "# print(y_test)\n",
        "yTestNew = y_test.argmax(axis=1)\n",
        "yPredNew100 = predictions100.argmax(axis=1)\n",
        "\n",
        "print(yTestNew)\n",
        "print(yPredNew100)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qczwcGHw_XIc"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "0o7HMFCs_XIc",
        "outputId": "b64729c1-0dea-4cbc-dea1-e4b9f67547f9"
      },
      "source": [
        "#For Model batch size 100\n",
        "\n",
        "cM = confusion_matrix(yTestNew,yPredNew100)\n",
        "\n",
        "displayClasses = [i for i in range(3)]\n",
        "\n",
        "print(f1_score(yTestNew, yPredNew100, average='macro'))\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cM, display_labels=displayClasses)\n",
        "disp.plot()\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8897954182258889\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}